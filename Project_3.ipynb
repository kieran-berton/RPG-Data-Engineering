{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Understanding User Behavior\n",
    "### UC Berkeley W205 MIDS Spring 2021\n",
    "### Kieran Berton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I'll showcase how we can pull in event data with Kafka from the Flask API webserver running our mobile gaming app, use Spark to filter these events and land them in a Hadoop Distributed File System (HDFS), and how we can use Hive and Presto to then query the returned data and perform analysis on it. \n",
    "\n",
    "This notebook will primarily focus on the filtering done with Spark, but I will include notes referencing how data is generated and how it moves through our data pipeline into HDFS and into a queryable table, then I will show some simple examples of analysis we can do with the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Flask server can be started using the \"game_api.py\" file included in this repository with the following command. \n",
    "\n",
    "docker-compose exec mids env FLASK_APP=/w205/project-3-kieran-berton/game_api.py flask run --host 0.0.0.0\n",
    "\n",
    "Once it is up and running, we can create a Kafka topic where we will be writing events from the web server so they can be stored in HDFS using this command\n",
    "\n",
    "docker-compose exec kafka kafka-topics --create --topic events --partitions 1 --replication-factor 1 --if-not-exists --zookeeper zookeeper:32181\n",
    "\n",
    "For this project, we used several methods of creating sample hits to our web server, for example we began by using Apache bench to execute batch server calls using the commands below.\n",
    "\n",
    "docker-compose exec mids ab -n 10 -H \"Host: user1.comcast.com\" http://localhost:5000/\n",
    "\n",
    "docker-compose exec mids ab -n 10 -H \"Host: user1.comcast.com\" http://localhost:5000/purchase_a_sword\n",
    "\n",
    "docker-compose exec mids ab -n 10 -H \"Host: user1.comcast.com\" http://localhost:5000/buy_a_sword\n",
    "\n",
    "docker-compose exec mids ab -n 10 -H \"Host: user1.comcast.com\" http://localhost:5000/join_guild\n",
    "\n",
    "docker-compose exec mids ab -n 10 -H \"Host: user2.att.com\" http://localhost:5000/\n",
    "\n",
    "docker-compose exec mids ab -n 10 -H \"Host: user2.att.com\" http://localhost:5000/purchase_a_sword\n",
    "\n",
    "docker-compose exec mids ab -n 10 -H \"Host: user2.att.com\" http://localhost:5000/buy_a_sword\n",
    "\n",
    "docker-compose exec mids ab -n 10 -H \"Host: user2.att.com\" http://localhost:5000/join_guild\n",
    "\n",
    "As you can see, these commands try to contact four different pages on our web server: the home page, and the purchase_a_sword, buy_a_sword, and join_guild sub pages. We contact the server as if from two 'users' identified by the Host names 'user1.comcast.com' and 'user2.att.com'. Later we used Apache bench to run a continuous stream of server calls using the following command which makes 10 calls to the server, specifically the 'purchase_a_sword' sub page, every 5 seconds. \n",
    "\n",
    "while true; do docker-compose exec mids ab -n 10 -H \"Host: user1.comcast.com\" http://localhost:5000/purchase_a_sword; sleep 5; done\n",
    "\n",
    "Once the data is being written to Kafka, we can use Spark to extract the data, filter it, and then write it to HDFS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first read the json objects from the Kafka stream into a spark table called raw_events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#This function will extract the columns of interest from the json object stored in Kafka\n",
    "\n",
    "@udf('string')\n",
    "def munge_event(event_as_json):\n",
    "    event = json.loads(event_as_json)\n",
    "    event['Host'] = \"moe\"\n",
    "    event['Cache-Control'] = \"no-cache\"\n",
    "    return json.dumps(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "raw_events = spark \\\n",
    "        .read \\\n",
    "        .format(\"kafka\") \\\n",
    "        .option(\"kafka.bootstrap.servers\", \"kafka:29092\") \\\n",
    "        .option(\"subscribe\", \"events\") \\\n",
    "        .option(\"startingOffsets\", \"earliest\") \\\n",
    "        .option(\"endingOffsets\", \"latest\") \\\n",
    "        .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "munged_events = raw_events \\\n",
    "        .select(raw_events.value.cast('string').alias('raw'),\n",
    "                raw_events.timestamp.cast('string')) \\\n",
    "        .withColumn('munged', munge_event('raw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                 raw|           timestamp|              munged|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|{\"Host\": \"localho...|2021-04-16 20:16:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"localho...|2021-04-16 20:16:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"localho...|2021-04-16 20:16:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"localho...|2021-04-16 20:16:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"localho...|2021-04-16 20:16:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"localho...|2021-04-16 20:16:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"localho...|2021-04-16 20:16:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"localho...|2021-04-16 20:16:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"localho...|2021-04-16 20:16:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"localho...|2021-04-16 20:16:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"localho...|2021-04-16 20:16:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"localho...|2021-04-16 20:16:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"localho...|2021-04-16 20:16:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"localho...|2021-04-16 20:16:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"localho...|2021-04-16 20:16:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"localho...|2021-04-16 20:16:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"localho...|2021-04-16 20:16:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"localho...|2021-04-16 20:16:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"localho...|2021-04-16 20:16:...|{\"Host\": \"moe\", \"...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "munged_events.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then extract the events from this raw table to an extracted_events table with column correctly separated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "extracted_events = munged_events \\\n",
    "        .rdd \\\n",
    "        .map(lambda r: Row(timestamp=r.timestamp, **json.loads(r.munged))) \\\n",
    "        .toDF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then filter events based on their event_type in order to see only purchase sword events or other event types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sword_purchases = extracted_events \\\n",
    "        .filter(extracted_events.event_type == 'purchase_sword')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+----+-----------+--------------+--------------------+\n",
      "|Accept|Cache-Control|Host| User-Agent|    event_type|           timestamp|\n",
      "+------+-------------+----+-----------+--------------+--------------------+\n",
      "|   */*|     no-cache| moe|curl/7.47.0|purchase_sword|2021-04-16 20:16:...|\n",
      "|   */*|     no-cache| moe|curl/7.47.0|purchase_sword|2021-04-16 20:16:...|\n",
      "|   */*|     no-cache| moe|curl/7.47.0|purchase_sword|2021-04-16 20:16:...|\n",
      "|   */*|     no-cache| moe|curl/7.47.0|purchase_sword|2021-04-16 20:16:...|\n",
      "|   */*|     no-cache| moe|curl/7.47.0|purchase_sword|2021-04-16 20:16:...|\n",
      "|   */*|     no-cache| moe|curl/7.47.0|purchase_sword|2021-04-16 20:16:...|\n",
      "|   */*|     no-cache| moe|curl/7.47.0|purchase_sword|2021-04-16 20:16:...|\n",
      "|   */*|     no-cache| moe|curl/7.47.0|purchase_sword|2021-04-16 20:16:...|\n",
      "|   */*|     no-cache| moe|curl/7.47.0|purchase_sword|2021-04-16 20:16:...|\n",
      "+------+-------------+----+-----------+--------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sword_purchases.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "default_hits = extracted_events \\\n",
    "        .filter(extracted_events.event_type == 'default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+----+-----------+----------+--------------------+\n",
      "|Accept|Cache-Control|Host| User-Agent|event_type|           timestamp|\n",
      "+------+-------------+----+-----------+----------+--------------------+\n",
      "|   */*|     no-cache| moe|curl/7.47.0|   default|2021-04-16 20:16:...|\n",
      "|   */*|     no-cache| moe|curl/7.47.0|   default|2021-04-16 20:16:...|\n",
      "|   */*|     no-cache| moe|curl/7.47.0|   default|2021-04-16 20:16:...|\n",
      "|   */*|     no-cache| moe|curl/7.47.0|   default|2021-04-16 20:16:...|\n",
      "|   */*|     no-cache| moe|curl/7.47.0|   default|2021-04-16 20:16:...|\n",
      "|   */*|     no-cache| moe|curl/7.47.0|   default|2021-04-16 20:16:...|\n",
      "|   */*|     no-cache| moe|curl/7.47.0|   default|2021-04-16 20:16:...|\n",
      "|   */*|     no-cache| moe|curl/7.47.0|   default|2021-04-16 20:16:...|\n",
      "|   */*|     no-cache| moe|curl/7.47.0|   default|2021-04-16 20:16:...|\n",
      "|   */*|     no-cache| moe|curl/7.47.0|   default|2021-04-16 20:16:...|\n",
      "+------+-------------+----+-----------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "default_hits.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New with Week 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In week 12, we are adding two more event types, the buy_sword and join_guild events, which are associated with their own pages on the Flask server. The process of extraction is the same, we read from Kafka with Spark, filter for the event types we are interested in and then display them in a table. Except this week we also write the extracted events to HDFS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "@udf('boolean')\n",
    "def is_buy_sword(event_as_json):\n",
    "    event = json.loads(event_as_json)\n",
    "    if event['event_type'] == 'buy_sword':\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "@udf('boolean')\n",
    "def is_join_guild(event_as_json):\n",
    "    event = json.loads(event_as_json)\n",
    "    if event['event_type'] == 'join_guild':\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "raw_events = spark \\\n",
    "        .read \\\n",
    "        .format(\"kafka\") \\\n",
    "        .option(\"kafka.bootstrap.servers\", \"kafka:29092\") \\\n",
    "        .option(\"subscribe\", \"events\") \\\n",
    "        .option(\"startingOffsets\", \"earliest\") \\\n",
    "        .option(\"endingOffsets\", \"latest\") \\\n",
    "        .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+------+---------+------+--------------------+-------------+\n",
      "| key|               value| topic|partition|offset|           timestamp|timestampType|\n",
      "+----+--------------------+------+---------+------+--------------------+-------------+\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|     0|2021-04-16 20:21:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|     1|2021-04-16 20:21:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|     2|2021-04-16 20:21:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|     3|2021-04-16 20:21:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|     4|2021-04-16 20:21:...|            0|\n",
      "+----+--------------------+------+---------+------+--------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_events.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join Guild Events\n",
    "Here we filter for only join_guild events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "join_guild_events = raw_events \\\n",
    "        .select(raw_events.value.cast('string').alias('raw'),\n",
    "                raw_events.timestamp.cast('string')) \\\n",
    "        .filter(is_join_guild('raw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                 raw|           timestamp|\n",
      "+--------------------+--------------------+\n",
      "|{\"Accept\": \"*/*\",...|2021-04-16 20:21:...|\n",
      "|{\"Accept\": \"*/*\",...|2021-04-16 20:21:...|\n",
      "|{\"Accept\": \"*/*\",...|2021-04-16 20:21:...|\n",
      "|{\"Accept\": \"*/*\",...|2021-04-16 20:21:...|\n",
      "|{\"Accept\": \"*/*\",...|2021-04-16 20:21:...|\n",
      "|{\"Accept\": \"*/*\",...|2021-04-16 20:21:...|\n",
      "|{\"Accept\": \"*/*\",...|2021-04-16 20:21:...|\n",
      "|{\"Accept\": \"*/*\",...|2021-04-16 20:21:...|\n",
      "|{\"Accept\": \"*/*\",...|2021-04-16 20:21:...|\n",
      "|{\"Accept\": \"*/*\",...|2021-04-16 20:21:...|\n",
      "|{\"Accept\": \"*/*\",...|2021-04-16 20:22:...|\n",
      "|{\"Accept\": \"*/*\",...|2021-04-16 20:22:...|\n",
      "|{\"Accept\": \"*/*\",...|2021-04-16 20:22:...|\n",
      "|{\"Accept\": \"*/*\",...|2021-04-16 20:22:...|\n",
      "|{\"Accept\": \"*/*\",...|2021-04-16 20:22:...|\n",
      "|{\"Accept\": \"*/*\",...|2021-04-16 20:22:...|\n",
      "|{\"Accept\": \"*/*\",...|2021-04-16 20:22:...|\n",
      "|{\"Accept\": \"*/*\",...|2021-04-16 20:22:...|\n",
      "|{\"Accept\": \"*/*\",...|2021-04-16 20:22:...|\n",
      "|{\"Accept\": \"*/*\",...|2021-04-16 20:22:...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "join_guild_events.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we convert this table to a more readable tabular format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "extracted_join_guild_events = join_guild_events \\\n",
    "        .rdd \\\n",
    "        .map(lambda r: Row(timestamp=r.timestamp, **json.loads(r.raw))) \\\n",
    "        .toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+---------------+----------+-------------------+--------------------+\n",
      "|Accept|             Host|     User-Agent|event_type|         guild_type|           timestamp|\n",
      "+------+-----------------+---------------+----------+-------------------+--------------------+\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|swordsmith alliance|2021-04-16 20:21:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|swordsmith alliance|2021-04-16 20:21:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|swordsmith alliance|2021-04-16 20:21:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|swordsmith alliance|2021-04-16 20:21:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|swordsmith alliance|2021-04-16 20:21:...|\n",
      "+------+-----------------+---------------+----------+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extracted_join_guild_events.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#write join_guild events to a subfolder in HDFS for join_guild events in parquet format\n",
    "extracted_join_guild_events \\\n",
    "        .write \\\n",
    "        .mode('overwrite') \\\n",
    "        .parquet('/tmp/join_guild')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#read back in what we just wrote to HDFS\n",
    "join_guild = spark.read.parquet('/tmp/join_guild')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+---------------+----------+-------------------+--------------------+\n",
      "|Accept|             Host|     User-Agent|event_type|         guild_type|           timestamp|\n",
      "+------+-----------------+---------------+----------+-------------------+--------------------+\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|swordsmith alliance|2021-04-16 20:21:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|swordsmith alliance|2021-04-16 20:21:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|swordsmith alliance|2021-04-16 20:21:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|swordsmith alliance|2021-04-16 20:21:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|swordsmith alliance|2021-04-16 20:21:...|\n",
      "+------+-----------------+---------------+----------+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "join_guild.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even create a temporary table from what we read in from HDFS and query it using SQL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "join_guild.registerTempTable('join_guild')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "join_guild_spark_df = spark.sql(\"select * from join_guild where Host = 'user1.comcast.com'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+---------------+----------+-------------------+--------------------+\n",
      "|Accept|             Host|     User-Agent|event_type|         guild_type|           timestamp|\n",
      "+------+-----------------+---------------+----------+-------------------+--------------------+\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|swordsmith alliance|2021-04-16 20:21:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|swordsmith alliance|2021-04-16 20:21:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|swordsmith alliance|2021-04-16 20:21:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|swordsmith alliance|2021-04-16 20:21:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|swordsmith alliance|2021-04-16 20:21:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|swordsmith alliance|2021-04-16 20:21:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|swordsmith alliance|2021-04-16 20:21:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|swordsmith alliance|2021-04-16 20:21:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|swordsmith alliance|2021-04-16 20:21:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|swordsmith alliance|2021-04-16 20:21:...|\n",
      "+------+-----------------+---------------+----------+-------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "join_guild_spark_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can take the table of values returned from our SQL query and convert it into a Pandas table that we can do typical python analysis with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accept</th>\n",
       "      <th>Host</th>\n",
       "      <th>User-Agent</th>\n",
       "      <th>event_type</th>\n",
       "      <th>guild_type</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>*/*</td>\n",
       "      <td>user1.comcast.com</td>\n",
       "      <td>ApacheBench/2.3</td>\n",
       "      <td>join_guild</td>\n",
       "      <td>swordsmith alliance</td>\n",
       "      <td>2021-04-16 20:21:52.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*/*</td>\n",
       "      <td>user1.comcast.com</td>\n",
       "      <td>ApacheBench/2.3</td>\n",
       "      <td>join_guild</td>\n",
       "      <td>swordsmith alliance</td>\n",
       "      <td>2021-04-16 20:21:52.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*/*</td>\n",
       "      <td>user1.comcast.com</td>\n",
       "      <td>ApacheBench/2.3</td>\n",
       "      <td>join_guild</td>\n",
       "      <td>swordsmith alliance</td>\n",
       "      <td>2021-04-16 20:21:52.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>*/*</td>\n",
       "      <td>user1.comcast.com</td>\n",
       "      <td>ApacheBench/2.3</td>\n",
       "      <td>join_guild</td>\n",
       "      <td>swordsmith alliance</td>\n",
       "      <td>2021-04-16 20:21:52.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*/*</td>\n",
       "      <td>user1.comcast.com</td>\n",
       "      <td>ApacheBench/2.3</td>\n",
       "      <td>join_guild</td>\n",
       "      <td>swordsmith alliance</td>\n",
       "      <td>2021-04-16 20:21:52.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Accept               Host       User-Agent  event_type           guild_type  \\\n",
       "0    */*  user1.comcast.com  ApacheBench/2.3  join_guild  swordsmith alliance   \n",
       "1    */*  user1.comcast.com  ApacheBench/2.3  join_guild  swordsmith alliance   \n",
       "2    */*  user1.comcast.com  ApacheBench/2.3  join_guild  swordsmith alliance   \n",
       "3    */*  user1.comcast.com  ApacheBench/2.3  join_guild  swordsmith alliance   \n",
       "4    */*  user1.comcast.com  ApacheBench/2.3  join_guild  swordsmith alliance   \n",
       "\n",
       "                 timestamp  \n",
       "0  2021-04-16 20:21:52.078  \n",
       "1  2021-04-16 20:21:52.082  \n",
       "2  2021-04-16 20:21:52.084  \n",
       "3  2021-04-16 20:21:52.088  \n",
       "4   2021-04-16 20:21:52.09  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_guild_df = join_guild_spark_df.toPandas()\n",
    "join_guild_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accept</th>\n",
       "      <th>Host</th>\n",
       "      <th>User-Agent</th>\n",
       "      <th>event_type</th>\n",
       "      <th>guild_type</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>*/*</td>\n",
       "      <td>user1.comcast.com</td>\n",
       "      <td>ApacheBench/2.3</td>\n",
       "      <td>join_guild</td>\n",
       "      <td>swordsmith alliance</td>\n",
       "      <td>2021-04-16 20:21:52.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accept               Host       User-Agent  event_type  \\\n",
       "count      10                 10               10          10   \n",
       "unique      1                  1                1           1   \n",
       "top       */*  user1.comcast.com  ApacheBench/2.3  join_guild   \n",
       "freq       10                 10               10          10   \n",
       "\n",
       "                 guild_type                timestamp  \n",
       "count                    10                       10  \n",
       "unique                    1                       10  \n",
       "top     swordsmith alliance  2021-04-16 20:21:52.093  \n",
       "freq                     10                        1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_guild_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can ask questions like how many unique people joined a guild?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_guild_df.Host.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or what day did people join guilds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16\n",
       "1    16\n",
       "2    16\n",
       "3    16\n",
       "4    16\n",
       "5    16\n",
       "6    16\n",
       "7    16\n",
       "8    16\n",
       "9    16\n",
       "Name: Day, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_guild_df['Day']=[d.split(' ')[0].split('-')[2] for d in join_guild_df.timestamp]\n",
    "join_guild_df.Day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, everyone joined on the 16th of the month, when I was running this analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buy Sword \n",
    "\n",
    "Now we filter only for buy_sword events and repeat the same process of extracting from Kafka, writing to HDFS, reading back in the data we just wrote, creating a queryable temp table, then converting the table returned by SQL to a pandas dataframe and doing some simple analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#filter raw events for only buy_sword events using the 'is_buy_sword' function\n",
    "buy_sword_events = raw_events \\\n",
    "        .select(raw_events.value.cast('string').alias('raw'),\n",
    "                raw_events.timestamp.cast('string')) \\\n",
    "        .filter(is_buy_sword('raw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                 raw|           timestamp|\n",
      "+--------------------+--------------------+\n",
      "|{\"Host\": \"user1.c...|2021-04-16 20:21:...|\n",
      "|{\"Host\": \"user1.c...|2021-04-16 20:21:...|\n",
      "|{\"Host\": \"user1.c...|2021-04-16 20:21:...|\n",
      "|{\"Host\": \"user1.c...|2021-04-16 20:21:...|\n",
      "|{\"Host\": \"user1.c...|2021-04-16 20:21:...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "buy_sword_events.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "extracted_buy_sword_events = buy_sword_events \\\n",
    "        .rdd \\\n",
    "        .map(lambda r: Row(timestamp=r.timestamp, **json.loads(r.raw))) \\\n",
    "        .toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+---------------+----------+----------+--------------------+\n",
      "|Accept|             Host|     User-Agent|event_type|sword_type|           timestamp|\n",
      "+------+-----------------+---------------+----------+----------+--------------------+\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3| buy_sword|  scimitar|2021-04-16 20:21:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3| buy_sword|  scimitar|2021-04-16 20:21:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3| buy_sword|  scimitar|2021-04-16 20:21:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3| buy_sword|  scimitar|2021-04-16 20:21:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3| buy_sword|  scimitar|2021-04-16 20:21:...|\n",
      "+------+-----------------+---------------+----------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extracted_buy_sword_events.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#write to HDFS\n",
    "extracted_buy_sword_events \\\n",
    "        .write \\\n",
    "        .mode('overwrite') \\\n",
    "        .parquet('/tmp/buy_sword')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#read back in what we just wrote to HDFS\n",
    "buy_sword = spark.read.parquet('/tmp/buy_sword')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+---------------+----------+----------+--------------------+\n",
      "|Accept|             Host|     User-Agent|event_type|sword_type|           timestamp|\n",
      "+------+-----------------+---------------+----------+----------+--------------------+\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3| buy_sword|  scimitar|2021-04-16 20:21:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3| buy_sword|  scimitar|2021-04-16 20:21:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3| buy_sword|  scimitar|2021-04-16 20:21:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3| buy_sword|  scimitar|2021-04-16 20:21:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3| buy_sword|  scimitar|2021-04-16 20:21:...|\n",
      "+------+-----------------+---------------+----------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "buy_sword.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#make an SQL-queryable temp table\n",
    "buy_sword.registerTempTable('buy_sword')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#query it with SQL\n",
    "buy_sword_spark_df = spark.sql(\"select * from buy_sword where Host = 'user1.comcast.com'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+---------------+----------+----------+--------------------+\n",
      "|Accept|             Host|     User-Agent|event_type|sword_type|           timestamp|\n",
      "+------+-----------------+---------------+----------+----------+--------------------+\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3| buy_sword|  scimitar|2021-04-16 20:21:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3| buy_sword|  scimitar|2021-04-16 20:21:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3| buy_sword|  scimitar|2021-04-16 20:21:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3| buy_sword|  scimitar|2021-04-16 20:21:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3| buy_sword|  scimitar|2021-04-16 20:21:...|\n",
      "+------+-----------------+---------------+----------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "buy_sword_spark_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accept</th>\n",
       "      <th>Host</th>\n",
       "      <th>User-Agent</th>\n",
       "      <th>event_type</th>\n",
       "      <th>sword_type</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>*/*</td>\n",
       "      <td>user1.comcast.com</td>\n",
       "      <td>ApacheBench/2.3</td>\n",
       "      <td>buy_sword</td>\n",
       "      <td>scimitar</td>\n",
       "      <td>2021-04-16 20:21:48.404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*/*</td>\n",
       "      <td>user1.comcast.com</td>\n",
       "      <td>ApacheBench/2.3</td>\n",
       "      <td>buy_sword</td>\n",
       "      <td>scimitar</td>\n",
       "      <td>2021-04-16 20:21:48.407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*/*</td>\n",
       "      <td>user1.comcast.com</td>\n",
       "      <td>ApacheBench/2.3</td>\n",
       "      <td>buy_sword</td>\n",
       "      <td>scimitar</td>\n",
       "      <td>2021-04-16 20:21:48.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>*/*</td>\n",
       "      <td>user1.comcast.com</td>\n",
       "      <td>ApacheBench/2.3</td>\n",
       "      <td>buy_sword</td>\n",
       "      <td>scimitar</td>\n",
       "      <td>2021-04-16 20:21:48.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*/*</td>\n",
       "      <td>user1.comcast.com</td>\n",
       "      <td>ApacheBench/2.3</td>\n",
       "      <td>buy_sword</td>\n",
       "      <td>scimitar</td>\n",
       "      <td>2021-04-16 20:21:48.419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Accept               Host       User-Agent event_type sword_type  \\\n",
       "0    */*  user1.comcast.com  ApacheBench/2.3  buy_sword   scimitar   \n",
       "1    */*  user1.comcast.com  ApacheBench/2.3  buy_sword   scimitar   \n",
       "2    */*  user1.comcast.com  ApacheBench/2.3  buy_sword   scimitar   \n",
       "3    */*  user1.comcast.com  ApacheBench/2.3  buy_sword   scimitar   \n",
       "4    */*  user1.comcast.com  ApacheBench/2.3  buy_sword   scimitar   \n",
       "\n",
       "                 timestamp  \n",
       "0  2021-04-16 20:21:48.404  \n",
       "1  2021-04-16 20:21:48.407  \n",
       "2   2021-04-16 20:21:48.41  \n",
       "3  2021-04-16 20:21:48.413  \n",
       "4  2021-04-16 20:21:48.419  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#write to a pandas dataframe\n",
    "buy_sword_df = buy_sword_spark_df.toPandas()\n",
    "buy_sword_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accept</th>\n",
       "      <th>Host</th>\n",
       "      <th>User-Agent</th>\n",
       "      <th>event_type</th>\n",
       "      <th>sword_type</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>*/*</td>\n",
       "      <td>user1.comcast.com</td>\n",
       "      <td>ApacheBench/2.3</td>\n",
       "      <td>buy_sword</td>\n",
       "      <td>scimitar</td>\n",
       "      <td>2021-04-16 20:21:48.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accept               Host       User-Agent event_type sword_type  \\\n",
       "count      10                 10               10         10         10   \n",
       "unique      1                  1                1          1          1   \n",
       "top       */*  user1.comcast.com  ApacheBench/2.3  buy_sword   scimitar   \n",
       "freq       10                 10               10         10         10   \n",
       "\n",
       "                      timestamp  \n",
       "count                        10  \n",
       "unique                       10  \n",
       "top     2021-04-16 20:21:48.422  \n",
       "freq                          1  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buy_sword_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many people bought a sword?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buy_sword_df.Host.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What day of the month did people buy a sword?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16\n",
       "1    16\n",
       "2    16\n",
       "3    16\n",
       "4    16\n",
       "5    16\n",
       "6    16\n",
       "7    16\n",
       "8    16\n",
       "9    16\n",
       "Name: Day, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buy_sword_df['Day']=[d.split(' ')[0].split('-')[2] for d in buy_sword_df.timestamp]\n",
    "buy_sword_df.Day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New in Week 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this week, we are reading streaming data from Kafka, instead of static calls to the server. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, from_json\n",
    "from pyspark.sql.types import StructType, StructField, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#this function defines the schema of the data to be read in from Kafka\n",
    "def purchase_sword_event_schema():\n",
    "    \"\"\"\n",
    "    root\n",
    "    |-- Accept: string (nullable = true)\n",
    "    |-- Host: string (nullable = true)\n",
    "    |-- User-Agent: string (nullable = true)\n",
    "    |-- event_type: string (nullable = true)\n",
    "    |-- timestamp: string (nullable = true)\n",
    "    \"\"\"\n",
    "    return StructType([\n",
    "        StructField(\"Accept\", StringType(), True),\n",
    "        StructField(\"Host\", StringType(), True),\n",
    "        StructField(\"User-Agent\", StringType(), True),\n",
    "        StructField(\"event_type\", StringType(), True),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#again we have a filter for purchase_sword events\n",
    "@udf('boolean')\n",
    "def is_sword_purchase(event_as_json):\n",
    "    \"\"\"udf for filtering events\n",
    "    \"\"\"\n",
    "    event = json.loads(event_as_json)\n",
    "    if event['event_type'] == 'purchase_sword':\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#we read the raw events from Kafka\n",
    "raw_events = spark \\\n",
    "        .readStream \\\n",
    "        .format(\"kafka\") \\\n",
    "        .option(\"kafka.bootstrap.servers\", \"kafka:29092\") \\\n",
    "        .option(\"subscribe\", \"events\") \\\n",
    "        .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#then we filter for only the purchase_sword events\n",
    "sword_purchases = raw_events \\\n",
    "        .filter(is_sword_purchase(raw_events.value.cast('string'))) \\\n",
    "        .select(raw_events.value.cast('string').alias('raw_event'),\n",
    "                raw_events.timestamp.cast('string'),\n",
    "                from_json(raw_events.value.cast('string'),\n",
    "                          purchase_sword_event_schema()).alias('json')) \\\n",
    "        .select('raw_event', 'timestamp', 'json.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#then we create a 'sink' to capture the data being streamed in through Kafka\n",
    "sink = sword_purchases \\\n",
    "        .writeStream \\\n",
    "        .format(\"parquet\") \\\n",
    "        .option(\"checkpointLocation\", \"/tmp/checkpoints_for_sword_purchases\") \\\n",
    "        .option(\"path\", \"/tmp/sword_purchases\") \\\n",
    "        .trigger(processingTime=\"10 seconds\") \\\n",
    "        .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sink.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that the files are writing to HDFS by running this from a Linux command line on your machine\n",
    "\n",
    "docker-compose exec cloudera hadoop fs -ls /tmp/sword_purchases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then you can setup an external table of event data using Hive with these commands\n",
    "\n",
    "docker-compose exec cloudera hive\n",
    "\n",
    "create external table if not exists default.sword_purchases (Accept string, Host string, User_Agent string, event_type string, timestamp string) stored as parquet location '/tmp/sword_purchases'  tblproperties (\"parquet.compress\"=\"SNAPPY\");\n",
    "\n",
    "exit;\n",
    "\n",
    "#### And finally you can query the data using Presto\n",
    "\n",
    "docker-compose exec presto presto --server presto:8080 --catalog hive --schema default\n",
    "\n",
    "(Check what tables are available from Hive)\n",
    "\n",
    "show tables;\n",
    "\n",
    "(Query tables)\n",
    "\n",
    "select * from sword_purchases;\n",
    "\n",
    "(Count hits to the web server)\n",
    "\n",
    "select count(*) from sword_purchases;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully this has been an enlightening demonstration of how a big data pipeline can be used to extract information from a mobile app. Kafka, Spark, Hadoop and Presto are great tools for transferring, storing, and querying relevant business data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
